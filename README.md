# Modelo Predictivo de Salarios en el Sector de Datos para Europa

Este proyecto tiene como objetivo analizar los factores clave que influyen en los salarios del sector de datos y construir un modelo de machine learning capaz de predecir una remuneraciÃ³n competitiva para profesionales en el mercado europeo.

## ğŸ“œ DescripciÃ³n del Proyecto

A travÃ©s de un anÃ¡lisis exhaustivo de un dataset global de ofertas de empleo, este proyecto sigue un flujo de trabajo completo de ciencia de datos: desde la adquisiciÃ³n y limpieza de los datos, pasando por un profundo anÃ¡lisis exploratorio (EDA) y una robusta ingenierÃ­a de caracterÃ­sticas, hasta el entrenamiento y la evaluaciÃ³n de mÃºltiples modelos de regresiÃ³n para encontrar el predictor mÃ¡s preciso.

El resultado final es un modelo de `RandomForestRegressor` optimizado que explica aproximadamente el **87.7%** de la varianza salarial y una aplicaciÃ³n interactiva desarrollada con Streamlit para realizar predicciones en tiempo real.

## ğŸ“‹ Tabla de Contenidos

1.  [Estructura del Repositorio](#-estructura-del-repositorio)
2.  [Fuente de Datos](#-fuente-de-datos)
3.  [MetodologÃ­a](#-metodologÃ­a)
    - [Limpieza y AnÃ¡lisis Exploratorio (EDA)](#1-limpieza-y-anÃ¡lisis-exploratorio-eda)
    - [IngenierÃ­a de CaracterÃ­sticas (Feature Engineering)](#2-ingenierÃ­a-de-caracterÃ­sticas-feature-engineering)
    - [Entrenamiento y EvaluaciÃ³n del Modelo](#3-entrenamiento-y-evaluaciÃ³n-del-modelo)
4.  [Resultados](#-resultados)
5.  [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
6.  [CÃ³mo Ejecutar el Proyecto](#-cÃ³mo-ejecutar-el-proyecto)
7.  [Autor](#-autor)

## ğŸ“ Estructura del Repositorio

El repositorio estÃ¡ organizado de la siguiente manera para facilitar la reproducibilidad y comprensiÃ³n del proyecto:
```
.
â”œâ”€â”€ app_streamlit/
â”‚   â”œâ”€â”€ demo_modelo.py
â”‚   â”œâ”€â”€ mi_modelo_salarios.pkl
â”‚   â””â”€â”€ salarios_codificado.csv
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ procesed/
â”‚   â”‚   â””â”€â”€ salarios_codificado.csv
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ ai_job_dataset.csv
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â””â”€â”€ test.csv
â”‚   â””â”€â”€ train/
â”‚       â””â”€â”€ train.csv
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ PresentaciÃ³n.pdf
â”‚
â”œâ”€â”€ graficos/
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ ... 
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mi_modelo_salarios.pkl
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Fuentes.ipynb
â”‚   â”œâ”€â”€ 02_LimpiezaEDA.ipynb
â”‚   â””â”€â”€ 03_Entrenamiento_Evaluacion.ipynb
â”‚
â””â”€â”€ README.md
Â´Â´Â´
## ğŸ“Š Fuente de Datos

Los datos para este anÃ¡lisis fueron obtenidos de la plataforma Kaggle.

-   **Nombre del Dataset:** Global AI Job Market & Salary Trends 2025
-   **Enlace:** [Kaggle Dataset](https://www.kaggle.com/datasets/bismasajjad/global-ai-job-market-and-salary-trends-2025)
-   **DescripciÃ³n:** El conjunto de datos contiene informaciÃ³n sobre salarios reportados en diversos roles dentro del campo de la ciencia de datos a nivel mundial.

## ğŸ› ï¸ MetodologÃ­a

El proyecto se dividiÃ³ en tres fases principales, cada una documentada en su respectivo notebook.

### 1. Limpieza y AnÃ¡lisis Exploratorio (EDA)

En esta fase, se realizÃ³ un anÃ¡lisis profundo para entender las distribuciones y relaciones en los datos. Los hallazgos mÃ¡s importantes fueron:
-   **Sesgo Salarial:** La distribuciÃ³n de salarios estÃ¡ fuertemente sesgada a la derecha, con una mayorÃ­a de salarios en el rango bajo-medio.
-   **Impacto de la Experiencia:** Se confirmÃ³ una correlaciÃ³n positiva muy fuerte entre el nivel de experiencia (`EN`, `MI`, `SE`, `EX`) y el salario.
-   **Influencia del TamaÃ±o de la Empresa:** Las empresas de mayor tamaÃ±o (`M`, `L`) tienden a ofrecer salarios mÃ¡s competitivos.

### 2. IngenierÃ­a de CaracterÃ­sticas (Feature Engineering)

Para preparar los datos para el modelado, se aplicaron las siguientes transformaciones:
-   **Filtro GeogrÃ¡fico:** El anÃ¡lisis se acotÃ³ exclusivamente al **mercado europeo** para aumentar la relevancia de las predicciones.
-   **CodificaciÃ³n Ordinal:** Variables como `experience_level` y `company_size` fueron codificadas numÃ©ricamente para preservar su orden jerÃ¡rquico.
-   **One-Hot Encoding:** Variables categÃ³ricas como `company_location`, `industry` y `job_title` (top 20) fueron convertidas a formato dummy.
-   **Procesamiento de Texto:** Se extrajeron las **20 habilidades tÃ©cnicas mÃ¡s comunes** de la columna `required_skills` y se crearon nuevas columnas binarias para indicar su presencia en cada oferta.
-   **CreaciÃ³n de Variables:** Se generÃ³ la variable `is_international` para capturar si la residencia del empleado y la ubicaciÃ³n de la empresa son diferentes.

### 3. Entrenamiento y EvaluaciÃ³n del Modelo

Se adoptÃ³ una estrategia competitiva para encontrar el mejor modelo de regresiÃ³n:
-   **Algoritmos Probados:** `RandomForestRegressor`, `XGBoost` y `LightGBM`.
-   **OptimizaciÃ³n:** Se utilizÃ³ `RandomizedSearchCV` con validaciÃ³n cruzada para encontrar los mejores hiperparÃ¡metros de forma eficiente.
-   **MÃ©trica de EvaluaciÃ³n:** El **coeficiente de determinaciÃ³n (RÂ²)** fue la mÃ©trica principal para seleccionar el modelo ganador.

## ğŸ† Resultados

El modelo con mejor rendimiento fue el **RandomForestRegressor**, que, tras ser evaluado en un conjunto de datos de prueba completamente nuevo, obtuvo las siguientes mÃ©tricas:

| MÃ©trica                         | Valor         | InterpretaciÃ³n                                                 |
| ------------------------------- | ------------- | -------------------------------------------------------------- |
| **Coeficiente de DeterminaciÃ³n (RÂ²)** | `0.877`       | El modelo explica el **87.7%** de la variabilidad de los salarios. |
| **Error Absoluto Medio (MAE)** | `10,796.61 â‚¬` | En promedio, la predicciÃ³n del modelo se desvÃ­a en ~â‚¬10,800 del salario real. |

Estos resultados indican un alto poder predictivo y una precisiÃ³n notable, considerando la dispersiÃ³n de los salarios en el sector.

## ğŸš€ TecnologÃ­as Utilizadas

-   **Lenguaje:** Python 3.10
-   **LibrerÃ­as Principales:**
    -   `Pandas` y `NumPy` para la manipulaciÃ³n de datos.
    -   `Matplotlib` y `Seaborn` para la visualizaciÃ³n de datos.
    -   `Scikit-learn` para el preprocesamiento, entrenamiento y evaluaciÃ³n de modelos.
    -   `XGBoost` y `LightGBM` para modelos de boosting.
    -   `Streamlit` para la creaciÃ³n de la demo interactiva.
    -   `Pickle` para la serializaciÃ³n del modelo.

## ğŸ’» CÃ³mo Ejecutar el Proyecto

Para replicar este proyecto o ejecutar la demo en tu mÃ¡quina local, sigue estos pasos:

1.  **Clonar el repositorio:**
    ```bash
    git clone [https://github.com/tu-usuario/nombre-del-repositorio.git](https://github.com/tu-usuario/nombre-del-repositorio.git)
    cd nombre-del-repositorio
    ```

2.  **Crear un entorno virtual (recomendado):**
    ```bash
    python -m venv env
    source env/bin/activate  # En Windows: env\Scripts\activate
    ```

3.  **Instalar las dependencias:**
    AsegÃºrate de tener un archivo `requirements.txt` con el siguiente contenido y luego ejecuta el comando `pip`:
    
    *Contenido de `requirements.txt`:*
    ```
    numpy
    pandas
    matplotlib
    seaborn
    scikit-learn
    xgboost
    lightgbm
    streamlit
    ```

    *Comando de instalaciÃ³n:*
    ```bash
    pip install -r requirements.txt
    ```
4.  **Ejecutar la demo interactiva:**
    Una vez instaladas las dependencias, inicia la aplicaciÃ³n de Streamlit:
    ```bash
    streamlit run demo_modelo.py
    ```
    Se abrirÃ¡ una nueva pestaÃ±a en tu navegador con la aplicaciÃ³n para realizar predicciones.

5.  **Explorar los Notebooks:**
    Puedes abrir y ejecutar los notebooks (`.ipynb`) utilizando Jupyter Notebook o Jupyter Lab para ver el proceso de anÃ¡lisis y modelado en detalle.

## ğŸ‘¤ Autor

Desarrollado por **Eduardo JosÃ© Limones Contreras**.

-   **LinkedIn:** [Perfil de LinkedIn](https://www.linkedin.com/in/eduardo-jos%C3%A9-limones-contreras-b1348677/)
-   **Correo:** eduardo.limones.contreras@gmail.com
